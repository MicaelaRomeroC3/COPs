{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmzGRYsKyhijZ5hPAEYm22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicaelaRomeroC3/COPs/blob/main/03_Tablafechas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnnsyywdQOFU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN5m7uViQeiH",
        "outputId": "730aab27-9e6e-4ffc-f686-f6af4aaf13fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_historical = '/content/drive/MyDrive/COPS/DATA/3.HISTORICAL/llamadas.parquet'\n",
        "if os.path.exists(ruta_historical):\n",
        "    df = pd.read_parquet(ruta_historical)\n",
        "    print(f\"üìä Hist√≥rico cargado con {len(df)} registros.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ el archivo hist√≥rico. Aseg√∫rate de ejecutarlo antes.\")\n",
        "    exit()\n",
        "\n",
        "df_grouped = df.groupby('FECHA_EVALUACI√ìN').agg(\n",
        "    P1_percent=('P1', lambda x: round((x.mean()) * 100, 2)),\n",
        "    P2_percent=('P2', lambda x: round((x.mean()) * 100, 2)),\n",
        "    P3_percent=('P3', lambda x: round((x.mean()) * 100, 2)),\n",
        "    P4_percent=('P4', lambda x: round((x.mean()) * 100, 2)),\n",
        "    P5_percent=('P5', lambda x: round((x.mean()) * 100, 2)),\n",
        "    P6_percent=('P6', lambda x: round((x.mean()) * 100, 2)),\n",
        "    S1_percent=('S1', lambda x: round((x.mean()) * 100, 2)),\n",
        "    S2_percent=('S2', lambda x: round((x.mean()) * 100, 2)),\n",
        "    S3_percent=('S3', lambda x: round((x.mean()) * 100, 2)),\n",
        "    S4_percent=('S4', lambda x: round((x.mean()) * 100, 2)),\n",
        "    S5_percent=('S5M', lambda x: round((x.mean()) * 100, 2)),\n",
        "    C1_percent=('C1M', lambda x: round((x.mean()) * 100, 2)),\n",
        "    C2_percent=('C2M', lambda x: round((x.mean()) * 100, 2)),\n",
        "    T1_percent=('T1M', lambda x: round((x.mean()) * 100, 2)),\n",
        "    T2_percent=('T2M', lambda x: round((x.mean()) * 100, 2)),\n",
        "    T3_percent=('T3', lambda x: round((x.mean()) * 100, 2))\n",
        ").reset_index()\n",
        "df['total_registros'] = df.groupby('FECHA_EVALUACI√ìN')['FECHA_EVALUACI√ìN'].transform('count')\n",
        "total_registros = df.groupby('FECHA_EVALUACI√ìN')['total_registros'].max()\n",
        "df_grouped['total_registros'] = total_registros.values\n",
        "df_grouped['total_registros'] = df_grouped['total_registros'].astype(int)\n",
        "df_transposed = df_grouped.set_index('FECHA_EVALUACI√ìN').transpose()\n",
        "\n",
        "detalle_dict = {\n",
        "    'P1_percent': 'PRESENTACI√ìN, SALUDO CORPORATIVO Y GRABACI√ìN DE LA LLAMADA',\n",
        "    'P2_percent': 'IDENTIFICACI√ìN DEL INTERLOCUTOR - LOPD',\n",
        "    'P3_percent': 'ESCUCHA COMPRENSIVA Y EMP√ÅTICA',\n",
        "    'P4_percent': 'TRATO CORDIAL AL CLIENTE',\n",
        "    'P5_percent': 'RESPONSABILIDAD CORPORATIVA',\n",
        "    'P6_percent': 'DESPEDIDA CORPORATIVA',\n",
        "    'S1_percent': 'INFORMACI√ìN MOTIVO DE LA LLAMADA',\n",
        "    'S2_percent': 'SITUACI√ìN ACTUAL DEL DEUDOR',\n",
        "    'S3_percent': 'SONDEO: IDENTIFICAR CAPACIDAD DE PAGO Y DETECCI√ìN DE NECESIDADES',\n",
        "    'S4_percent': 'DIRECCI√ìN',\n",
        "    'S5_percent': 'PREPARACI√ìN CIERRE : RESUMEN DE ACUERDOS',\n",
        "    'C1_percent': 'OFRECER TPV COMO ALTERNATIVA PRIORITARIA DE PAGO',\n",
        "    'C2_percent': 'PRIORIZA LOS CANALES DIGITALES U OTROS MEDIOS PARA REALIZAR LOS INGRESOS LO ANTES POSIBLE',\n",
        "    'T1_percent': 'USO EFECTIVO DEL SCRIPT',\n",
        "    'T2_percent': 'CAPACIDAD DE EXPRESI√ìN',\n",
        "    'T3_percent': 'BUSCAR EL COMPROMISO DE PAGO ENUNCIANDO LOS BENEFICIOS Y LAS CONSECUENCIAS DE LA REGULARIZACI√ìN'\n",
        "}\n",
        "\n",
        "# Renombrar las filas (√≠ndice) del DataFrame transpuesto\n",
        "df_transposed.insert(0, 'DETALLE', df_transposed.index.map(detalle_dict))\n",
        "\n",
        "# Diccionario AGRUPADOR\n",
        "agrupador_dict = {\n",
        "    'P1_percent': 'PRESENTACI√ìN',\n",
        "    'P2_percent': 'PRESENTACI√ìN',\n",
        "    'P3_percent': 'PRESENTACI√ìN',\n",
        "    'P4_percent': 'PRESENTACI√ìN',\n",
        "    'P5_percent': 'PRESENTACI√ìN',\n",
        "    'P6_percent': 'PRESENTACI√ìN',\n",
        "    'S1_percent': 'SONDEO',\n",
        "    'S2_percent': 'SONDEO',\n",
        "    'S3_percent': 'SONDEO',\n",
        "    'S4_percent': 'SONDEO',\n",
        "    'S5_percent': 'SONDEO',\n",
        "    'C1_percent': 'CANALIZACION',\n",
        "    'C2_percent': 'CANALIZACION',\n",
        "    'T1_percent': 'SCRIPT',\n",
        "    'T2_percent': 'SCRIPT',\n",
        "    'T3_percent': 'SCRIPT',\n",
        "    'total_registros': 'TOTAL'\n",
        "}\n",
        "\n",
        "# Insertar columna AGRUPADOR\n",
        "df_transposed.insert(0, 'AGRUPADOR', df_transposed.index.map(agrupador_dict))\n",
        "\n",
        "# Ponderaciones\n",
        "ponderacion_dict = {\n",
        "    'P1_percent': 0.02,\n",
        "    'P2_percent': 0.10,\n",
        "    'P3_percent': 0.03,\n",
        "    'P4_percent': 0.03,\n",
        "    'P5_percent': 0.05,\n",
        "    'P6_percent': 0.02,\n",
        "    'S1_percent': 0.03,\n",
        "    'S2_percent': 0.02,\n",
        "    'S3_percent': 0.10,\n",
        "    'S4_percent': 0.10,\n",
        "    'S5_percent': 0.05,\n",
        "    'C1_percent': 0.10,\n",
        "    'C2_percent': 0.10,\n",
        "    'T1_percent': 0.05,\n",
        "    'T2_percent': 0.10,\n",
        "    'T3_percent': 0.10\n",
        "}\n",
        "\n",
        "df_transposed.insert(0, 'PONDERACION', df_transposed.index.map(ponderacion_dict))\n",
        "\n",
        "df_transposed.loc[df_transposed.index == 'GLOBAL', 'PONDERACION'] = ''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnepAlyiQody",
        "outputId": "f23ce5da-7f56-4818-fddc-96819ade18d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Hist√≥rico cargado con 10000 registros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2972139022.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_transposed.loc[df_transposed.index == 'GLOBAL', 'PONDERACION'] = ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Para calcular los % de las categorias agrupadas\n",
        "\n",
        "df_presentacion = df_transposed[df_transposed['AGRUPADOR'].str.upper().str.strip() == 'PRESENTACI√ìN'].copy()\n",
        "\n",
        "# Paso 2: Aseg√∫rate de que la columna PONDERACION es float (en formato 0.02, 0.10, etc)\n",
        "df_presentacion['PONDERACION'] = (\n",
        "    df_presentacion['PONDERACION']\n",
        "    .astype(str)\n",
        "    .str.replace('%', '', regex=False)\n",
        "    .str.replace(',', '.', regex=False)\n",
        "    .astype(float) / 100\n",
        ")\n",
        "\n",
        "# Paso 3: Seleccionar solo las columnas de fechas\n",
        "columnas_fechas = [col for col in df_transposed.columns if col not in ['INDICADOR', 'AGRUPADOR', 'PONDERACION', 'DETALLE']]\n",
        "\n",
        "\n",
        "# Paso 4: Calcular la ponderaci√≥n * valor para cada fila\n",
        "ponderados = df_presentacion[columnas_fechas].multiply(df_presentacion['PONDERACION'].values, axis=0)\n",
        "\n",
        "# Paso 5: Sumar los valores ponderados por columna\n",
        "suma_ponderada = ponderados.sum(axis=0)\n",
        "\n",
        "# Paso 6: Dividir entre 0.25 (peso total del grupo ‚ÄúPresentaci√≥n‚Äù)\n",
        "resultado_presentacion = (suma_ponderada / 0.25)*100\n",
        "\n",
        "# Paso 7: Crear nueva fila con resultado\n",
        "fila_presentacion = pd.DataFrame([['PRESENTACI√ìN', 'PRESENTACI√ìN', '', *resultado_presentacion]],\n",
        "                                 columns=['INDICADOR', 'AGRUPADOR', 'PONDERACION'] + columnas_fechas)\n",
        "\n",
        "# Paso 8: Insertar la nueva fila al inicio del dataframe\n",
        "df_transposed = pd.concat([fila_presentacion, df_transposed], ignore_index=True)\n",
        "\n",
        "def agregar_indicador_grupo(df_transposed, nombre_grupo, peso_grupo):\n",
        "    # Paso 1: Filtrar el grupo (en may√∫sculas y sin espacios)\n",
        "    df_grupo = df_transposed[df_transposed['AGRUPADOR'].str.upper().str.strip() == nombre_grupo.upper()].copy()\n",
        "\n",
        "    # Paso 2: Asegurar que PONDERACION est√° en float\n",
        "    df_grupo['PONDERACION'] = (\n",
        "        df_grupo['PONDERACION']\n",
        "        .astype(str)\n",
        "        .str.replace('%', '', regex=False)\n",
        "        .str.replace(',', '.', regex=False)\n",
        "        .astype(float) / 100\n",
        "    )\n",
        "\n",
        "    # Paso 3: Seleccionar solo columnas de fechas\n",
        "    columnas_fechas = [col for col in df_transposed.columns if col not in ['INDICADOR', 'AGRUPADOR', 'PONDERACION', 'DETALLE']]\n",
        "\n",
        "    # Paso 4: Asegurar que los valores de fechas est√°n en float\n",
        "    df_grupo[columnas_fechas] = df_grupo[columnas_fechas].apply(\n",
        "        lambda col: col.astype(str)\n",
        "                     .str.replace('%', '', regex=False)\n",
        "                     .str.replace(',', '.', regex=False)\n",
        "                     .astype(float) / 100\n",
        "    )\n",
        "\n",
        "    # Paso 5: Multiplicar cada fila por su ponderaci√≥n\n",
        "    ponderados = df_grupo[columnas_fechas].multiply(df_grupo['PONDERACION'].values, axis=0)\n",
        "\n",
        "    # Paso 6: Sumar por columna\n",
        "    suma_ponderada = ponderados.sum(axis=0)\n",
        "\n",
        "    # Paso 7: Dividir entre el peso total del grupo\n",
        "    resultado = ((suma_ponderada / peso_grupo) )* 100\n",
        "\n",
        "    # Paso 8: Crear fila de resultado\n",
        "    fila = pd.DataFrame([[nombre_grupo.upper(), nombre_grupo.upper(), '', *resultado]],\n",
        "                        columns=['INDICADOR', 'AGRUPADOR', 'PONDERACION'] + columnas_fechas)\n",
        "\n",
        "    # Paso 9: Agregar fila al inicio\n",
        "    return pd.concat([fila, df_transposed], ignore_index=True)\n",
        "\n",
        "df_transposed = agregar_indicador_grupo(df_transposed, 'SONDEO', 0.003)\n",
        "df_transposed = agregar_indicador_grupo(df_transposed, 'SCRIPT', 0.0025)\n",
        "df_transposed = agregar_indicador_grupo(df_transposed, 'CANALIZACION', 0.0020)\n",
        "\n",
        "# 1Ô∏è‚É£ Ordenar filas seg√∫n el orden deseado en 'INDICADOR'\n",
        "orden_indicadores = ['PRESENTACI√ìN', 'SONDEO', 'CANALIZACION', 'SCRIPT']\n",
        "df_transposed['INDICADOR'] = df_transposed['INDICADOR'].astype(str)\n",
        "df_transposed['orden_temp'] = df_transposed['INDICADOR'].apply(\n",
        "    lambda x: orden_indicadores.index(x.upper()) if x.upper() in orden_indicadores else len(orden_indicadores)\n",
        ")\n",
        "df_transposed = df_transposed.sort_values(by='orden_temp').drop(columns='orden_temp').reset_index(drop=True)\n",
        "\n",
        "# 2Ô∏è‚É£ Reordenar las columnas para que DETALLE est√© justo despu√©s de AGRUPADOR\n",
        "columnas_ordenadas = ['INDICADOR', 'AGRUPADOR', 'DETALLE', 'PONDERACION'] + [\n",
        "    col for col in df_transposed.columns if col not in ['INDICADOR', 'AGRUPADOR', 'DETALLE', 'PONDERACION']\n",
        "]\n",
        "df_transposed = df_transposed[columnas_ordenadas]\n",
        "\n",
        "# Crear la ruta completa\n",
        "ruta_salida = '/content/drive/MyDrive/COPS/OUTPUT/TABLA_FECHAS.xlsx'\n",
        "\n",
        "# Crear la carpeta si no existe\n",
        "os.makedirs(os.path.dirname(ruta_salida), exist_ok=True)\n",
        "\n",
        "# Suponemos que las fechas empiezan desde la columna √≠ndice 4 (columna 5 visualmente)\n",
        "columnas_fechas = df_transposed.columns[4:]\n",
        "\n",
        "# Copiamos y multiplicamos por la ponderaci√≥n\n",
        "df_transposed_copy = df_transposed.copy()\n",
        "\n",
        "for col in columnas_fechas:\n",
        "    df_transposed_copy[col] = df_transposed_copy[col].astype(float) * pd.to_numeric(df_transposed_copy['PONDERACION'], errors='coerce').fillna(0)\n",
        "\n",
        "# Sumamos para obtener la fila GLOBAL\n",
        "fila_global = df_transposed_copy[columnas_fechas].sum()\n",
        "\n",
        "# Creamos la nueva fila\n",
        "nueva_fila = pd.Series(index=df_transposed.columns, dtype='object')\n",
        "nueva_fila['INDICADOR'] = 'GLOBAL'\n",
        "nueva_fila['AGRUPADOR'] = 'GLOBAL'\n",
        "nueva_fila['DETALLE'] = ''\n",
        "nueva_fila['PONDERACION'] = ''\n",
        "for col in columnas_fechas:\n",
        "    nueva_fila[col] = fila_global[col]\n",
        "\n",
        "# Insertamos la fila GLOBAL antes de la fila PRESENTACI√ìN\n",
        "idx_presentacion = df_transposed[df_transposed['INDICADOR'] == 'PRESENTACI√ìN'].index[0]\n",
        "df_transposed = pd.concat([\n",
        "    df_transposed.iloc[:idx_presentacion],\n",
        "    pd.DataFrame([nueva_fila]),\n",
        "    df_transposed.iloc[idx_presentacion:]\n",
        "]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "1HwDjXPdQ33E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame transpuesto en el archivo Excel\n",
        "with pd.ExcelWriter(ruta_salida, engine='openpyxl') as writer:\n",
        "    df_transposed.to_excel(writer, sheet_name='TABLA_FECHAS', index=False)\n",
        "\n",
        "print(f\"‚úÖ El archivo ha sido guardado correctamente en: {ruta_salida}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juaycgw6RFIf",
        "outputId": "0878a3f7-93ea-48e0-e8f5-56dd5083d666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ El archivo ha sido guardado correctamente en: /content/drive/MyDrive/COPS/OUTPUT/TABLA_FECHAS.xlsx\n"
          ]
        }
      ]
    }
  ]
}